"""
quantum_tests.py

‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≠‡∏ô‡∏ï‡∏±‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
- ‡∏™‡∏£‡πâ‡∏≤‡∏á Entanglement Graph ‡∏à‡∏≤‡∏Å MI Matrix
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î Bell-like Inequality
- ‡∏ß‡∏±‡∏î KL-Divergence ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Entropy Distribution
- ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö quantum_utilities.py

‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤: Apichet & Quantum Mechanics GPT
"""

import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
from scipy.stats import entropy as scipy_entropy

from quantum_utilities import build_entanglement_graph


# ------------------------------
# üìä Visualize Entanglement Network
# ------------------------------

def plot_entanglement_network(mi_matrix: np.ndarray, threshold: float = 0.1) -> nx.Graph:
    """
    ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏±‡∏ß‡∏û‡∏±‡∏ô (Entanglement Graph) ‡∏à‡∏≤‡∏Å Mutual Information Matrix

    Args:
        mi_matrix (np.ndarray): ‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå mutual information [n x n]
        threshold (float): ‡∏Ñ‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á node

    Returns:
        networkx.Graph: ‡∏Å‡∏£‡∏≤‡∏ü‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏±‡∏ß‡∏û‡∏±‡∏ô
    """
    G = build_entanglement_graph(mi_matrix, threshold)
    pos = nx.spring_layout(G, seed=42)

    plt.figure(figsize=(10, 8))
    nx.draw(G, pos, with_labels=True, node_size=500, node_color="skyblue", edge_color="gray")
    plt.title(f"Quantum Entanglement Graph (Threshold = {threshold})")
    plt.tight_layout()
    plt.show()

    return G


# ------------------------------
# üî¨ Bell-like Inequality Test
# ------------------------------

def test_bell_violation(mi_matrix: np.ndarray, threshold: float = 0.1) -> int:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î Bell-like Inequality ‡πÅ‡∏ö‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:
    ‡∏ñ‡πâ‡∏≤ MI(A,B) + MI(B,C) < MI(A,C) - threshold ‚Üí ‡∏≠‡∏≤‡∏à‡∏°‡∏µ non-local correlation

    Args:
        mi_matrix (np.ndarray): Mutual information matrix
        threshold (float): ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ

    Returns:
        int: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î
    """
    violations = 0
    n = mi_matrix.shape[0]

    for a in range(n):
        for b in range(n):
            for c in range(n):
                if a != b and b != c and a != c:
                    lhs = mi_matrix[a, b] + mi_matrix[b, c]
                    rhs = mi_matrix[a, c]
                    if lhs < rhs - threshold:
                        violations += 1

    print(f"üîî Bell-like violations detected: {violations}")
    return violations


# ------------------------------
# üìâ KL Divergence between distributions
# ------------------------------

def kl_divergence(p_real: np.ndarray, p_sim: np.ndarray) -> float:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì KL Divergence ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 probability distributions

    Args:
        p_real (np.ndarray): Distribution ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
        p_sim (np.ndarray): Distribution ‡∏à‡∏≤‡∏Å RNG

    Returns:
        float: ‡∏Ñ‡πà‡∏≤ KL divergence
    """
    p_real = np.asarray(p_real) + 1e-9  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô log(0)
    p_sim = np.asarray(p_sim) + 1e-9
    kl = scipy_entropy(p_real, p_sim)
    print(f"üìè KL-Divergence = {kl:.5f}")
    return kl


# ------------------------------
# üìà Optional: Compare Distributions
# ------------------------------

def plot_entropy_distributions(real_entropies, sim_entropies, bins=30):
    """
    ‡∏ß‡∏≤‡∏î histogram ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö entropy ‡∏Ç‡∏≠‡∏á draw ‡∏à‡∏£‡∏¥‡∏á vs ‡∏™‡∏∏‡πà‡∏°

    Args:
        real_entropies (list): ‡∏Ñ‡πà‡∏≤ entropy ‡∏Ç‡∏≠‡∏á draw ‡∏à‡∏£‡∏¥‡∏á
        sim_entropies (list): ‡∏Ñ‡πà‡∏≤ entropy ‡∏Ç‡∏≠‡∏á draw ‡∏à‡∏≤‡∏Å RNG
    """
    plt.figure(figsize=(10, 5))
    plt.hist(real_entropies, bins=bins, alpha=0.6, label="Real Draws", color='blue')
    plt.hist(sim_entropies, bins=bins, alpha=0.6, label="Pure RNG", color='orange')
    plt.axvline(np.mean(real_entropies), color='blue', linestyle='--', label='Mean Real Entropy')
    plt.axvline(np.mean(sim_entropies), color='orange', linestyle='--', label='Mean RNG Entropy')
    plt.xlabel("Entropy")
    plt.ylabel("Frequency")
    plt.title("Entropy Distribution: Real vs RNG")
    plt.legend()
    plt.tight_layout()
    plt.show()
